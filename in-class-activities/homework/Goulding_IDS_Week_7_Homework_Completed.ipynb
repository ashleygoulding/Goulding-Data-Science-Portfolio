{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1: Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Preview:\n",
      "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
      "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
      "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
      "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
      "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
      "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
      "\n",
      "   Longitude  \n",
      "0    -122.23  \n",
      "1    -122.22  \n",
      "2    -122.24  \n",
      "3    -122.25  \n",
      "4    -122.25  \n",
      "\n",
      "Feature names: ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
      "\n",
      "Missing values per column:\n",
      "MedInc        0\n",
      "HouseAge      0\n",
      "AveRooms      0\n",
      "AveBedrms     0\n",
      "Population    0\n",
      "AveOccup      0\n",
      "Latitude      0\n",
      "Longitude     0\n",
      "dtype: int64\n",
      "\n",
      "Summary Statistics:\n",
      "             MedInc      HouseAge      AveRooms     AveBedrms    Population  \\\n",
      "count  20640.000000  20640.000000  20640.000000  20640.000000  20640.000000   \n",
      "mean       3.870671     28.639486      5.429000      1.096675   1425.476744   \n",
      "std        1.899822     12.585558      2.474173      0.473911   1132.462122   \n",
      "min        0.499900      1.000000      0.846154      0.333333      3.000000   \n",
      "25%        2.563400     18.000000      4.440716      1.006079    787.000000   \n",
      "50%        3.534800     29.000000      5.229129      1.048780   1166.000000   \n",
      "75%        4.743250     37.000000      6.052381      1.099526   1725.000000   \n",
      "max       15.000100     52.000000    141.909091     34.066667  35682.000000   \n",
      "\n",
      "           AveOccup      Latitude     Longitude  \n",
      "count  20640.000000  20640.000000  20640.000000  \n",
      "mean       3.070655     35.631861   -119.569704  \n",
      "std       10.386050      2.135952      2.003532  \n",
      "min        0.692308     32.540000   -124.350000  \n",
      "25%        2.429741     33.930000   -121.800000  \n",
      "50%        2.818116     34.260000   -118.490000  \n",
      "75%        3.282261     37.710000   -118.010000  \n",
      "max     1243.333333     41.950000   -114.310000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import streamlit as st\n",
    "\n",
    "# Load the housing dataset\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X = pd.DataFrame(housing.data, columns=housing.feature_names) \n",
    "y = pd.Series(housing.target, name='med_house_value')\n",
    "\n",
    "#Display the first five rows of the dataset. (5 pts)\n",
    "print(\"\\nDataset Preview:\")\n",
    "print(X.head())\n",
    "\n",
    "#Print the feature names and check for missing values. (5 pts)\n",
    "print(\"\\nFeature names:\", X.columns.tolist())\n",
    "\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(X.isnull().sum())\n",
    "\n",
    "#Generate summary statistics (mean, min, max, etc.). (10 pts)\n",
    "\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(X.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2: Linear Regression on Unscaled Data (30 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      "[0.71912284 1.76401657 2.70965883 ... 4.46877017 1.18751119 2.00940251]\n",
      "\n",
      "Model Coefficients (Unscaled):\n",
      "MedInc        0.448675\n",
      "HouseAge      0.009724\n",
      "AveRooms     -0.123323\n",
      "AveBedrms     0.783145\n",
      "Population   -0.000002\n",
      "AveOccup     -0.003526\n",
      "Latitude     -0.419792\n",
      "Longitude    -0.433708\n",
      "dtype: float64\n",
      "\n",
      "Model Intercept (Unscaled):\n",
      "0   -37.023278\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Split the dataset into training and test sets (80% training, 20% testing). (5 pts)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, \n",
    "                                                            test_size=0.2, \n",
    "                                                            random_state=42)\n",
    "\n",
    "#Train a linear regression model on the unscaled data using sklearn.linear_model.LinearRegression. (5 pts)\n",
    "lin_reg_raw = LinearRegression()\n",
    "lin_reg_raw.fit(X_train_raw, y_train)\n",
    "\n",
    "#Make predictions on the test set. (5 pts)\n",
    "y_pred_raw = lin_reg_raw.predict(X_test_raw)\n",
    "print(\"Predictions:\")\n",
    "print(y_pred_raw)\n",
    "\n",
    "# View our model's coefficients\n",
    "print(\"\\nModel Coefficients (Unscaled):\")\n",
    "print(pd.Series(lin_reg_raw.coef_,\n",
    "                index=X.columns))\n",
    "print(\"\\nModel Intercept (Unscaled):\")\n",
    "print(pd.Series(lin_reg_raw.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unscaled Data Model:\n",
      "Mean Squared Error: 0.56\n",
      "Root Squared Error: 0.75\n",
      "R² Score: 0.58\n"
     ]
    }
   ],
   "source": [
    "#Evaluate model performance using the following metrics:\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error, r2_score\n",
    "\n",
    "#Mean Squared Error (MSE) (5 pts)\n",
    "\n",
    "mse_raw = mean_squared_error(y_test, y_pred_raw)\n",
    "print(\"Unscaled Data Model:\")\n",
    "print(f\"Mean Squared Error: {mse_raw:.2f}\")\n",
    "\n",
    "#Root Mean Squared Error (RMSE) (5 pts)\n",
    "\n",
    "rmse_raw = root_mean_squared_error(y_test, y_pred_raw)\n",
    "print(f\"Root Squared Error: {rmse_raw:.2f}\")\n",
    "\n",
    "#R² Score (5 pts)\n",
    "\n",
    "r2_raw = r2_score(y_test, y_pred_raw)\n",
    "print(f\"R² Score: {r2_raw:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation Questions:\n",
    "\n",
    "What does the R² score tell us about model performance?\n",
    "\n",
    "The R² score is 0.58, which means the model explains about 58% of the variance in housing prices. This is a moderate level of explanatory power which means the model captures some important patterns in the data, but there’s still a significant amount of variation left unexplained, which could indicate missing features  in the data.\n",
    "\n",
    "Which features seem to have the strongest impact on predictions based on the model’s coefficients?\n",
    "\n",
    "Based on the model’s coefficients, the features with the strongest impact on predictions are Average Bedrooms per Household (AveBedrms), Median Income (MedInc), and Longitude and Latitude. Specifically, AveBedrms has the largest positive influence, meaning that neighborhoods with more bedrooms per household tend to have higher predicted housing prices. MedInc also has a strong positive effect, indicating that areas with higher median incomes tend to see higher prices. In contrast, both Longitude and Latitude have significant negative coefficients, meaning that moving further north or east tends to lower predicted housing prices, likely reflecting regional price patterns within California. \n",
    "\n",
    "How well do the predicted values match the actual values?\n",
    "\n",
    "Based on the MSE of 0.56 and the RMSE of 0.75, the model’s predictions are fairly close to the actual values since lower MSE and RMSE values indicate better predictive performance. The RMSE of 0.75 tells us that the average prediction is about 0.75 units off from the true value. This is a moderate level of accuracy: the model captures the general trend of the data, but the errors are large enough to suggest room for improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 4: Feature Selection and Simplified Model (25 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select three features from the dataset to build a simplified model. Explain your choice. \n",
    "\n",
    "For the simplified model, I would select MedInc (Median Income), AveBedrms (Average Bedrooms per Household), and Longitutde. These three features had the coefficients with the largest magnitude and capture key drivers of housing prices while keeping the model manageable and interpretable. \n",
    "\n",
    "AveBedrms had the highest coefficient of .783 which indicates that the number of bedrooms in a home is strongly positively correlated with how valuable it is and is the largest predictor of housing prices. MedInc had the second largest coefficient of .449, as higher income neighborhoods tend to have higher housing prices, reflecting purchasing power. Finally, Longitude captures geographic variation in pricing, which is crucial in a dataset covering California, where location strongly influences home values and southern most houses tended to be more expensive. Together, these three features balance economic factors, physical housing characteristics, and location effects, providing a well-rounded foundation for a simplified predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unscaled Data Model:\n",
      "Mean Squared Error: 0.70\n",
      "Root Squared Error: 0.84\n",
      "R² Score: 0.47\n"
     ]
    }
   ],
   "source": [
    "#Train a new linear regression model using only these three features. (5 pts)\n",
    "\n",
    "x= pd.DataFrame(housing.data, columns=housing.feature_names)[['MedInc', 'AveBedrms', 'Latitude']]  # Features\n",
    "Y = pd.Series(housing.target, name='med_house_value')  # Target variable\n",
    "\n",
    "x_train, x_test, Y_train, Y_test = train_test_split(x, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "newmodel = LinearRegression()\n",
    "newmodel.fit(x_train, Y_train)\n",
    "\n",
    "Y_pred = newmodel.predict(x_test)\n",
    "\n",
    "#Evaluate the performance of this simplified model and compare it to the full model. (5 pts)\n",
    "\n",
    "mse_raw2 = mean_squared_error(Y_test, Y_pred)\n",
    "print(\"Unscaled Data Model:\")\n",
    "print(f\"Mean Squared Error: {mse_raw2:.2f}\")\n",
    "\n",
    "rmse_raw2 = root_mean_squared_error(Y_test, Y_pred)\n",
    "print(f\"Root Squared Error: {rmse_raw2:.2f}\")\n",
    "\n",
    "r2_raw2 = r2_score(Y_test, Y_pred)\n",
    "print(f\"R² Score: {r2_raw2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation Questions:\n",
    "\n",
    "How does the simplified model compare to the full model?\n",
    "\n",
    "The simplified model, which uses only three features, shows higher error metrics compared to the full model. Specifically, the Mean Squared Error (MSE) is 0.70, and the Root Mean Squared Error (RMSE) is 0.84. These higher values suggest that the simplified model makes less accurate predictions than the full model. Additionally, the R² score for the simplified model is 0.47, meaning it only explains 47% of the variance in housing prices. In contrast, the full model, with more features, has a higher R² score of .58 and better explains the variability in the target variable. This indicates that the full model, with its greater number of features, is better at capturing the underlying patterns in the data and making more accurate predictions.\n",
    "\n",
    "Would you use this simplified model in practice? Why or why not?\n",
    "\n",
    "In practice, I would consider using the simplified model, despite its slightly lower accuracy compared to the full model. The R² score of 0.47 and the error metrics, while not perfect, are not drastically worse than those of the more complex model. Given that the simplified model uses only three features, it will be much easier to implement and interpret. Additionally, using fewer features means there is less data required for training, which can be advantageous in situations where data collection is expensive or time-consuming. For practical applications where a quick, cost-effective solution is needed, the simplified model offers a reasonable trade-off between performance and ease of use. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlitenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
